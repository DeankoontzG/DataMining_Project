{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24a151b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AGGLO  : ../../cluster_results/clusters_annotes/clusters_annotes_clusters_umap_agglomerative.csv\n",
      "✅ KMEANS : ../../cluster_results/clusters_annotes/clusters_annotes_clusters_umap_kmeans_5.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Robustesse & stabilité des clusters (UMAP — Agglomerative & K-Means)\n",
    "\n",
    "# %%\n",
    "import os, re, glob, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score as ARI,\n",
    "    normalized_mutual_info_score as NMI,\n",
    "    silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Dossiers\n",
    "BASE_DIR = \"../../cluster_results\"\n",
    "IN_DIR   = os.path.join(BASE_DIR, \"clusters_annotes\")\n",
    "OUT_DIR  = os.path.join(BASE_DIR, \"robustness\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Fichiers attendus (avec tolérance de nommage)\n",
    "FILE_AGGLO_CANDIDATES = [\n",
    "    os.path.join(IN_DIR, \"clusters_annotes_clusters_umap_agglomerative.csv\"),\n",
    "    os.path.join(IN_DIR, \"clusters_annotes_umap_agglomerative.csv\"),\n",
    "]\n",
    "FILE_KMEANS_CANDIDATES = [\n",
    "    os.path.join(IN_DIR, \"clusters_annotes_clusters_umap_kmeans_5.csv\"),  # tel que fourni\n",
    "    os.path.join(IN_DIR, \"clusters_annotes_clusters_umap_kmeans_5.csv\"),\n",
    "    os.path.join(IN_DIR, \"clusters_annotes_clusters_umap_kmeans_5.csv\"),\n",
    "]\n",
    "\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "FILE_AGGLO  = first_existing(FILE_AGGLO_CANDIDATES)\n",
    "FILE_KMEANS = first_existing(FILE_KMEANS_CANDIDATES)\n",
    "\n",
    "if FILE_AGGLO is None or FILE_KMEANS is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Introuvable :\\n\"\n",
    "        f\"  AGGLO candidates : {FILE_AGGLO_CANDIDATES}\\n\"\n",
    "        f\"  KMEANS candidates : {FILE_KMEANS_CANDIDATES}\"\n",
    "    )\n",
    "\n",
    "print(\"✅ AGGLO  :\", FILE_AGGLO)\n",
    "print(\"✅ KMEANS :\", FILE_KMEANS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a515a349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGLO  → X:(341, 8), k=5, coords=['per90_gls', 'per90_ast', 'carries_prog']...\n",
      "KMEANS → X:(341, 8), k=5, coords=['per90_gls', 'per90_ast', 'carries_prog']...\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Chargement & détection des colonnes d'embedding\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "META_COLS = [\"player_name\", \"positions\", \"equipe\", \"team\", \"tag\", \"cluster\"]\n",
    "\n",
    "def load_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"cluster\" not in df.columns:\n",
    "        raise ValueError(f\"'cluster' manquant dans {path}\")\n",
    "    return df\n",
    "\n",
    "def detect_coord_columns(df: pd.DataFrame):\n",
    "    \"\"\"Privilégie umap_*, tsne_*, pca_*, isomap_* ; sinon toutes numériques hors méta/cluster.\"\"\"\n",
    "    prefixes = (\"umap\", \"tsne\", \"pca\", \"isomap\")\n",
    "    coord_cols = [c for c in df.columns if any(p in c.lower() for p in prefixes)]\n",
    "    coord_cols = [c for c in coord_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if len(coord_cols) >= 2:\n",
    "        return coord_cols\n",
    "    # fallback: numériques hors méta\n",
    "    meta_set = set(META_COLS)\n",
    "    return [c for c in df.select_dtypes(include=[np.number]).columns if c not in meta_set]\n",
    "\n",
    "df_agglo  = load_df(FILE_AGGLO)\n",
    "df_kmeans = load_df(FILE_KMEANS)\n",
    "\n",
    "cols_agglo  = detect_coord_columns(df_agglo)\n",
    "cols_kmeans = detect_coord_columns(df_kmeans)\n",
    "\n",
    "X_agglo  = df_agglo[cols_agglo].to_numpy(dtype=float)\n",
    "X_kmeans = df_kmeans[cols_kmeans].to_numpy(dtype=float)\n",
    "\n",
    "y_agglo  = df_agglo[\"cluster\"].to_numpy()\n",
    "y_kmeans = df_kmeans[\"cluster\"].to_numpy()\n",
    "\n",
    "k_agglo  = np.unique(y_agglo[y_agglo!=-1]).size if (-1 in y_agglo) else np.unique(y_agglo).size\n",
    "k_kmeans = np.unique(y_kmeans[y_kmeans!=-1]).size if (-1 in y_kmeans) else np.unique(y_kmeans).size\n",
    "\n",
    "print(f\"AGGLO  → X:{X_agglo.shape}, k={k_agglo}, coords={cols_agglo[:3]}{'...' if len(cols_agglo)>3 else ''}\")\n",
    "print(f\"KMEANS → X:{X_kmeans.shape}, k={k_kmeans}, coords={cols_kmeans[:3]}{'...' if len(cols_kmeans)>3 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9314dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Fonctions : stabilité (bootstrap), robustesse (bruit), indices internes\n",
    "\n",
    "# %%\n",
    "RANDOM_STATE   = 42\n",
    "N_BOOTSTRAPS   = 20\n",
    "NOISE_LEVELS   = [0.01, 0.03, 0.05]  # 1%, 3%, 5% d'écart-type par feature\n",
    "\n",
    "def recluster(X, method: str, k: int, seed: int):\n",
    "    if method == \"kmeans\":\n",
    "        return KMeans(n_clusters=k, n_init=10, random_state=seed).fit_predict(X)\n",
    "    if method == \"agglomerative\":\n",
    "        return AgglomerativeClustering(n_clusters=k, linkage=\"ward\").fit_predict(X)\n",
    "    raise ValueError(\"Méthode non supportée\")\n",
    "\n",
    "def stability_bootstrap(X: np.ndarray, y_base: np.ndarray, method: str, k: int, n_iter: int):\n",
    "    \"\"\"Resample indices avec remise, recluster, compare aux labels de base sur l'échantillon (ARI/NMI).\"\"\"\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    ari, nmi = [], []\n",
    "    n = len(y_base)\n",
    "    for i in range(n_iter):\n",
    "        X_res, idx = resample(X, np.arange(n), replace=True, random_state=RANDOM_STATE+i)\n",
    "        y_res = recluster(X_res, method, k, seed=RANDOM_STATE+i)\n",
    "        ari.append(ARI(y_base[idx], y_res))\n",
    "        nmi.append(NMI(y_base[idx], y_res))\n",
    "    return np.mean(ari), np.std(ari), np.mean(nmi), np.std(nmi)\n",
    "\n",
    "def robustness_noise(X: np.ndarray, y_base: np.ndarray, method: str, k: int, levels):\n",
    "    \"\"\"Ajoute du bruit gaussien (par feature), recluster, compare aux labels de base sur tout X.\"\"\"\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    mu, sigma = X.mean(axis=0), X.std(axis=0) + 1e-12\n",
    "    rows = []\n",
    "    for lvl in levels:\n",
    "        noise = rng.normal(0, sigma*lvl, size=X.shape)\n",
    "        Xn = X + noise\n",
    "        y_new = recluster(Xn, method, k, seed=RANDOM_STATE+int(lvl*100))\n",
    "        rows.append({\n",
    "            \"noise_pct\": int(lvl*100),\n",
    "            \"ARI\": ARI(y_base, y_new),\n",
    "            \"NMI\": NMI(y_base, y_new),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def internal_indices(X: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"Indices internes sur les labels fournis (si ≥2 clusters).\"\"\"\n",
    "    unique = np.unique(y[y!=-1]) if (-1 in y) else np.unique(y)\n",
    "    if unique.size < 2:\n",
    "        return dict(silhouette=np.nan, calinski=np.nan, davies=np.nan)\n",
    "    return dict(\n",
    "        silhouette = float(silhouette_score(X, y)),\n",
    "        calinski   = float(calinski_harabasz_score(X, y)),\n",
    "        davies     = float(davies_bouldin_score(X, y)),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc8aa71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sanitize] NaN imputés: 6 | shape=(341, 8)\n",
      "[sanitize] NaN imputés: 6 | shape=(341, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>method</th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>ARI_mean</th>\n",
       "      <th>ARI_std</th>\n",
       "      <th>NMI_mean</th>\n",
       "      <th>NMI_std</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>calinski</th>\n",
       "      <th>davies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clusters_annotes_clusters_umap_agglomerative.csv</td>\n",
       "      <td>agglomerative</td>\n",
       "      <td>341</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>-0.0721</td>\n",
       "      <td>17.28</td>\n",
       "      <td>7.1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clusters_annotes_clusters_umap_kmeans_5.csv</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>341</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>-0.0448</td>\n",
       "      <td>13.71</td>\n",
       "      <td>8.1248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file         method    n  k  \\\n",
       "0  clusters_annotes_clusters_umap_agglomerative.csv  agglomerative  341  5   \n",
       "1       clusters_annotes_clusters_umap_kmeans_5.csv         kmeans  341  5   \n",
       "\n",
       "   ARI_mean  ARI_std  NMI_mean  NMI_std  silhouette  calinski  davies  \n",
       "0    0.0741   0.0364    0.1637   0.0355     -0.0721     17.28  7.1092  \n",
       "1    0.0700   0.0277    0.1335   0.0349     -0.0448     13.71  8.1248  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_pct</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.041946</td>\n",
       "      <td>0.118427</td>\n",
       "      <td>agglomerative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.137377</td>\n",
       "      <td>0.210646</td>\n",
       "      <td>agglomerative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.114104</td>\n",
       "      <td>0.208644</td>\n",
       "      <td>agglomerative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.101829</td>\n",
       "      <td>kmeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.042615</td>\n",
       "      <td>0.098538</td>\n",
       "      <td>kmeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.042878</td>\n",
       "      <td>0.090091</td>\n",
       "      <td>kmeans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_pct       ARI       NMI         method\n",
       "0          1  0.041946  0.118427  agglomerative\n",
       "1          3  0.137377  0.210646  agglomerative\n",
       "2          5  0.114104  0.208644  agglomerative\n",
       "3          1  0.049520  0.101829         kmeans\n",
       "4          3  0.042615  0.098538         kmeans\n",
       "5          5  0.042878  0.090091         kmeans"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sauvegardes :\n",
      " - ../../cluster_results/robustness/robustness_stability_summary.csv\n",
      " - ../../cluster_results/robustness/robustness_noise_sensitivity.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Lancer les tests (avec assainissement des NaN/Inf) et sauvegarder les résumés\n",
    "\n",
    "# %%\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def sanitize_X(X: np.ndarray):\n",
    "    \"\"\"Remplace ±Inf par NaN puis impute les NaN par la médiane par colonne.\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    X[~np.isfinite(X)] = np.nan  # ±Inf -> NaN\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    X_clean = imp.fit_transform(X)\n",
    "    n_nan = np.isnan(X).sum()\n",
    "    print(f\"[sanitize] NaN imputés: {n_nan} | shape={X.shape}\")\n",
    "    return X_clean\n",
    "\n",
    "# Assainir les matrices avant tests\n",
    "X_agglo_clean  = sanitize_X(X_agglo)\n",
    "X_kmeans_clean = sanitize_X(X_kmeans)\n",
    "\n",
    "summ_rows = []\n",
    "noise_details = []\n",
    "\n",
    "# ---- Agglomerative ----\n",
    "ari_mu, ari_sd, nmi_mu, nmi_sd = stability_bootstrap(X_agglo_clean, y_agglo, \"agglomerative\", k_agglo, N_BOOTSTRAPS)\n",
    "ints = internal_indices(X_agglo_clean, y_agglo)\n",
    "df_noise_agg = robustness_noise(X_agglo_clean, y_agglo, \"agglomerative\", k_agglo, NOISE_LEVELS)\n",
    "df_noise_agg[\"method\"] = \"agglomerative\"\n",
    "noise_details.append(df_noise_agg)\n",
    "\n",
    "summ_rows.append({\n",
    "    \"file\": os.path.basename(FILE_AGGLO),\n",
    "    \"method\": \"agglomerative\",\n",
    "    \"n\": len(y_agglo),\n",
    "    \"k\": k_agglo,\n",
    "    \"ARI_mean\": round(ari_mu, 4),\n",
    "    \"ARI_std\": round(ari_sd, 4),\n",
    "    \"NMI_mean\": round(nmi_mu, 4),\n",
    "    \"NMI_std\": round(nmi_sd, 4),\n",
    "    \"silhouette\": round(ints[\"silhouette\"], 4) if not np.isnan(ints[\"silhouette\"]) else np.nan,\n",
    "    \"calinski\": round(ints[\"calinski\"], 2) if not np.isnan(ints[\"calinski\"]) else np.nan,\n",
    "    \"davies\": round(ints[\"davies\"], 4) if not np.isnan(ints[\"davies\"]) else np.nan,\n",
    "})\n",
    "\n",
    "# ---- K-Means ----\n",
    "ari_mu, ari_sd, nmi_mu, nmi_sd = stability_bootstrap(X_kmeans_clean, y_kmeans, \"kmeans\", k_kmeans, N_BOOTSTRAPS)\n",
    "ints = internal_indices(X_kmeans_clean, y_kmeans)\n",
    "df_noise_km = robustness_noise(X_kmeans_clean, y_kmeans, \"kmeans\", k_kmeans, NOISE_LEVELS)\n",
    "df_noise_km[\"method\"] = \"kmeans\"\n",
    "noise_details.append(df_noise_km)\n",
    "\n",
    "summ_rows.append({\n",
    "    \"file\": os.path.basename(FILE_KMEANS),\n",
    "    \"method\": \"kmeans\",\n",
    "    \"n\": len(y_kmeans),\n",
    "    \"k\": k_kmeans,\n",
    "    \"ARI_mean\": round(ari_mu, 4),\n",
    "    \"ARI_std\": round(ari_sd, 4),\n",
    "    \"NMI_mean\": round(nmi_mu, 4),\n",
    "    \"NMI_std\": round(nmi_sd, 4),\n",
    "    \"silhouette\": round(ints[\"silhouette\"], 4) if not np.isnan(ints[\"silhouette\"]) else np.nan,\n",
    "    \"calinski\": round(ints[\"calinski\"], 2) if not np.isnan(ints[\"calinski\"]) else np.nan,\n",
    "    \"davies\": round(ints[\"davies\"], 4) if not np.isnan(ints[\"davies\"]) else np.nan,\n",
    "})\n",
    "\n",
    "# ---- Sauvegardes ----\n",
    "df_summary = pd.DataFrame(summ_rows)\n",
    "df_noise   = pd.concat(noise_details, ignore_index=True)\n",
    "\n",
    "sum_path   = os.path.join(OUT_DIR, \"robustness_stability_summary.csv\")\n",
    "noise_path = os.path.join(OUT_DIR, \"robustness_noise_sensitivity.csv\")\n",
    "\n",
    "df_summary.to_csv(sum_path, index=False)\n",
    "df_noise.to_csv(noise_path, index=False)\n",
    "\n",
    "display(df_summary)\n",
    "display(df_noise)\n",
    "\n",
    "print(f\"✅ Sauvegardes :\\n - {sum_path}\\n - {noise_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb782066",
   "metadata": {},
   "source": [
    "# ## Interprétation (à insérer dans le rapport)\n",
    "#\n",
    "# - **Stabilité (bootstrap / ARI, NMI)** : des moyennes élevées (et faibles écarts-types)\n",
    "#   signifient que la partition est peu sensible au rééchantillonnage des joueurs.\n",
    "# - **Robustesse au bruit** : si ARI/NMI restent élevés quand on injecte 1–5% de bruit\n",
    "#   (gaussien, par feature), la structure des clusters est robuste aux petites variations\n",
    "#   de l'embedding UMAP.\n",
    "# - **Indices internes** :\n",
    "#   - Silhouette ↑ et Davies-Bouldin ↓ indiquent de meilleurs séparations/compacité,\n",
    "#     Calinski-Harabasz ↑ reflète des clusters compacts et bien séparés.\n",
    "# - **Comparaison méthodes** :\n",
    "#   - Si Agglomerative > K-Means sur ARI/NMI et indices internes, il capte mieux des sous-profils.\n",
    "#   - Si K-Means est proche en scores, **sa simplicité** en fait un très bon compromis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
