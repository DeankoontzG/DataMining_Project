{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68d76c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le dossier parent au path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Ensuite tu peux importer ton module\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "992c81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & paramètres\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import utils  # doit fournir utils.load_data(pattern)\n",
    "\n",
    "# Réglages\n",
    "INPUT_GLOB = \"../../cleaned_data/*.csv\"\n",
    "OUT_DIR_COORDS = \"./reduced_data_pca\"\n",
    "OUT_METRICS_CSV = \"./reduced_data_pca/pca_metrics.csv\"\n",
    "VAR_THRESHOLD = 0.90\n",
    "N_NEIGHBORS_TRUST = 10\n",
    "RANDOM_STATE = 0\n",
    "K_NEIGHBORS_EVAL = 3  # k pour trustworthiness, continuity, mrre (sera clampé au n-1)\n",
    "\n",
    "\n",
    "os.makedirs(OUT_DIR_COORDS, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b536132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Utilitaires\n",
    "def ensure_dict_datasets(obj, default_name=\"merged\"):\n",
    "    \"\"\"Accepte un DataFrame unique OU un dict[str, DataFrame].\"\"\"\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return {default_name: obj}\n",
    "    if isinstance(obj, dict):\n",
    "        return obj\n",
    "    raise TypeError(\"utils.load_data doit retourner un DataFrame ou un dict[str, DataFrame].\")\n",
    "\n",
    "def pick_meta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Retourne les colonnes méta disponibles : player_name, equipe, positions.\"\"\"\n",
    "    tmp = df.copy()\n",
    "    if \"positions\" not in tmp.columns and \"position\" in tmp.columns:\n",
    "        tmp = tmp.rename(columns={\"position\": \"positions\"})\n",
    "    meta_cols = [c for c in [\"player_name\", \"equipe\", \"positions\"] if c in tmp.columns]\n",
    "    return tmp[meta_cols] if meta_cols else pd.DataFrame(index=tmp.index)\n",
    "\n",
    "def compute_distance_correlation(X_high: np.ndarray, X_low: np.ndarray) -> float:\n",
    "    \"\"\"Corrélation de Pearson entre matrices de distances (triangle supérieur).\"\"\"\n",
    "    D_high = pairwise_distances(X_high, metric=\"euclidean\")\n",
    "    D_low  = pairwise_distances(X_low,  metric=\"euclidean\")\n",
    "    iu = np.triu_indices_from(D_high, k=1)\n",
    "    v1, v2 = D_high[iu], D_low[iu]\n",
    "    if v1.std() == 0 or v2.std() == 0:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(v1, v2)[0, 1])\n",
    "\n",
    "def clamp_neighbors(n_samples: int, n_neighbors: int) -> int:\n",
    "    return max(1, min(n_neighbors, max(1, n_samples - 1)))\n",
    "\n",
    "def continuity(X: np.ndarray, X_embedded: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Continuity (Kaski & Venna): 1 = parfait, 0 = mauvais.\"\"\"\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    n = X.shape[0]\n",
    "    k = clamp_neighbors(n, k)\n",
    "\n",
    "    orig_nn = np.argsort(pairwise_distances(X), axis=1)[:, 1:k+1]\n",
    "    emb_nn  = np.argsort(pairwise_distances(X_embedded), axis=1)[:, 1:k+1]\n",
    "\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        orig = list(orig_nn[i])\n",
    "        emb_set = set(emb_nn[i])\n",
    "        missing = [m for m in orig if m not in emb_set]\n",
    "        # pénalité = rang (1..k) des voisins manquants dans l'espace original\n",
    "        total += sum(orig.index(m) + 1 for m in missing)\n",
    "\n",
    "    denom = n * k * (2 * n - 3 * k - 1)\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return 1 - (2 / denom) * total\n",
    "\n",
    "def mrre(X: np.ndarray, X_embedded: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Mean Relative Rank Error (MRRE): 0 = parfait (mieux), plus grand = pire.\"\"\"\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    n = X.shape[0]\n",
    "    k = clamp_neighbors(n, k)\n",
    "\n",
    "    D_high = pairwise_distances(X)\n",
    "    D_low  = pairwise_distances(X_embedded)\n",
    "\n",
    "    # Rangs (1..n)\n",
    "    R_high = np.argsort(np.argsort(D_high, axis=1), axis=1) + 1\n",
    "    R_low  = np.argsort(np.argsort(D_low,  axis=1), axis=1) + 1\n",
    "\n",
    "    err = 0.0\n",
    "    cnt = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            denom = R_high[i, j]\n",
    "            if denom <= 0:\n",
    "                continue\n",
    "            err += abs(R_high[i, j] - R_low[i, j]) / denom\n",
    "            cnt += 1\n",
    "    return float(err / cnt) if cnt > 0 else float('nan')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bcba2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell - 3\n",
    "def run_pca_once(df: pd.DataFrame, var_threshold=0.90, random_state=0):\n",
    "    Xnum = df.select_dtypes(include=[np.number]).copy()\n",
    "    if Xnum.shape[1] < 2:\n",
    "        return None\n",
    "\n",
    "    X_imp = SimpleImputer(strategy=\"mean\").fit_transform(Xnum.values)\n",
    "    X_std = StandardScaler().fit_transform(X_imp)\n",
    "\n",
    "    pca = PCA(n_components=None, random_state=random_state)\n",
    "    scores_all = pca.fit_transform(X_std)\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    k = int(np.searchsorted(cumvar, var_threshold) + 1)\n",
    "\n",
    "    scores_k = scores_all[:, :k]\n",
    "    cols = [f\"pca{i+1}\" for i in range(k)]\n",
    "    coords_df = pd.DataFrame(scores_k, index=df.index, columns=cols)\n",
    "\n",
    "    # Métriques\n",
    "    nn_trust = clamp_neighbors(X_std.shape[0], N_NEIGHBORS_TRUST)\n",
    "    tw = trustworthiness(X_std, scores_k, n_neighbors=nn_trust)\n",
    "\n",
    "    nn_eval = clamp_neighbors(X_std.shape[0], K_NEIGHBORS_EVAL)\n",
    "    cont = continuity(X_std, scores_k, k=nn_eval)\n",
    "    mrre_score = mrre(X_std, scores_k, k=K_NEIGHBORS_EVAL)\n",
    "    \n",
    "    dist_corr = compute_distance_correlation(X_std, scores_k)\n",
    "\n",
    "\n",
    "    # cast sûrs (évite float(None))\n",
    "    def safe_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return float('nan')\n",
    "\n",
    "    return {\n",
    "        \"k\": k,\n",
    "        \"coords\": coords_df,\n",
    "        \"explained_var\": safe_float(pca.explained_variance_ratio_[:k].sum()),\n",
    "        \"trustworthiness\": safe_float(tw),\n",
    "        \"continuity\": safe_float(cont),\n",
    "        \"mrre\": safe_float(mrre_score),\n",
    "        \"distance_correlation\": safe_float(dist_corr),\n",
    "\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f57a6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data: [Errno 2] No such file or directory: '../../cleaned_data/*.csv'\n",
      "Fallback: lecture directe des CSV via glob.\n",
      "4 jeux trouvés.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['joueurs_ligue1_2024_2025_clean_custom',\n",
       " 'joueurs_ligue1_2024_2025_clean_custom_no_GK',\n",
       " 'joueurs_ligue1_2024_2025_clean_per90',\n",
       " 'joueurs_ligue1_2024_2025_clean_raw']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 — Chargement des jeux de données (robuste)\n",
    "import glob\n",
    "\n",
    "def _to_dict_datasets(obj):\n",
    "    \"\"\"Normalise en dict[str, DataFrame] les formes possibles.\"\"\"\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return {\"merged\": obj}\n",
    "    if isinstance(obj, dict):\n",
    "        return obj\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        out = {}\n",
    "        for i, item in enumerate(obj):\n",
    "            # format: (name, df)\n",
    "            if isinstance(item, (list, tuple)) and len(item) == 2 and isinstance(item[1], pd.DataFrame):\n",
    "                out[str(item[0])] = item[1]\n",
    "            # format: df seul\n",
    "            elif isinstance(item, pd.DataFrame):\n",
    "                out[f\"df_{i}\"] = item\n",
    "        if out:\n",
    "            return out\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    raw = utils.load_data(INPUT_GLOB)  # peut renvoyer df / dict / liste\n",
    "except Exception as e:\n",
    "    print(f\"utils.load_data a échoué: {e}\")\n",
    "    raw = None\n",
    "\n",
    "datasets = _to_dict_datasets(raw)\n",
    "\n",
    "# Fallback: lecture directe des CSV si rien d'exploitable\n",
    "if datasets is None:\n",
    "    print(\"Fallback: lecture directe des CSV via glob.\")\n",
    "    paths = sorted(glob.glob(INPUT_GLOB))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"Aucun fichier trouvé avec le motif: {INPUT_GLOB}\")\n",
    "    datasets = {\n",
    "        os.path.splitext(os.path.basename(p))[0]: pd.read_csv(p)\n",
    "        for p in paths\n",
    "    }\n",
    "\n",
    "print(f\"{len(datasets)} jeux trouvés.\")\n",
    "list(datasets.keys())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c40bb459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] joueurs_ligue1_2024_2025_clean_custom: k=33, var=0.901, trust=0.998, dist_corr=0.997 -> ./reduced_data_pca/joueurs_ligue1_2024_2025_clean_custom_pca_33d.csv\n",
      "[OK] joueurs_ligue1_2024_2025_clean_custom_no_GK: k=34, var=0.902, trust=0.998, dist_corr=0.998 -> ./reduced_data_pca/joueurs_ligue1_2024_2025_clean_custom_no_GK_pca_34d.csv\n",
      "[OK] joueurs_ligue1_2024_2025_clean_per90: k=29, var=0.900, trust=0.998, dist_corr=0.997 -> ./reduced_data_pca/joueurs_ligue1_2024_2025_clean_per90_pca_29d.csv\n",
      "[OK] joueurs_ligue1_2024_2025_clean_raw: k=23, var=0.904, trust=0.998, dist_corr=0.998 -> ./reduced_data_pca/joueurs_ligue1_2024_2025_clean_raw_pca_23d.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Boucle: PCA + sauvegardes + collecte métriques\n",
    "metrics_rows = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    res = run_pca_once(df, var_threshold=VAR_THRESHOLD, random_state=RANDOM_STATE)\n",
    "    if res is None:\n",
    "        print(f\"[SKIP] {name}: < 2 colonnes numériques.\")\n",
    "        continue\n",
    "\n",
    "    k = res[\"k\"]\n",
    "    coords = res[\"coords\"]  # pca1..pcak\n",
    "    meta = pick_meta(df)\n",
    "    out_df = coords.join(meta, how=\"left\")\n",
    "\n",
    "    # nom fichier sortie\n",
    "    base = str(name)\n",
    "    if base.endswith(\".csv\"):\n",
    "        base = os.path.splitext(os.path.basename(base))[0]\n",
    "    safe_name = base.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    out_path = os.path.join(OUT_DIR_COORDS, f\"{safe_name}_pca_{k}d.csv\")\n",
    "\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"dataset\": safe_name,\n",
    "        \"n_components\": k,\n",
    "        \"explained_variance_cum\": res[\"explained_var\"],\n",
    "        \"trustworthiness_k\": res[\"trustworthiness\"],\n",
    "        \"continuity_k\": res[\"continuity\"],\n",
    "        \"mrre_k\": res[\"mrre\"],\n",
    "        \"out_file\": out_path,\n",
    "        \"distance_corr\": res[\"distance_correlation\"]\n",
    "    })\n",
    "\n",
    "    print(f\"[OK] {safe_name}: k={k}, var={res['explained_var']:.3f}, \"\n",
    "          f\"trust={res['trustworthiness']:.3f}, dist_corr={res['distance_correlation']:.3f} -> {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "747b8fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_components</th>\n",
       "      <th>explained_variance_cum</th>\n",
       "      <th>trustworthiness_k</th>\n",
       "      <th>continuity_k</th>\n",
       "      <th>mrre_k</th>\n",
       "      <th>out_file</th>\n",
       "      <th>distance_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joueurs_ligue1_2024_2025_clean_custom</td>\n",
       "      <td>33</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.997791</td>\n",
       "      <td>0.998450</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>./reduced_data_pca/joueurs_ligue1_2024_2025_cl...</td>\n",
       "      <td>0.997459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joueurs_ligue1_2024_2025_clean_custom_no_GK</td>\n",
       "      <td>34</td>\n",
       "      <td>0.902434</td>\n",
       "      <td>0.997912</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.063516</td>\n",
       "      <td>./reduced_data_pca/joueurs_ligue1_2024_2025_cl...</td>\n",
       "      <td>0.997852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joueurs_ligue1_2024_2025_clean_per90</td>\n",
       "      <td>29</td>\n",
       "      <td>0.900209</td>\n",
       "      <td>0.997883</td>\n",
       "      <td>0.998059</td>\n",
       "      <td>0.067810</td>\n",
       "      <td>./reduced_data_pca/joueurs_ligue1_2024_2025_cl...</td>\n",
       "      <td>0.997254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joueurs_ligue1_2024_2025_clean_raw</td>\n",
       "      <td>23</td>\n",
       "      <td>0.904024</td>\n",
       "      <td>0.997656</td>\n",
       "      <td>0.998129</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>./reduced_data_pca/joueurs_ligue1_2024_2025_cl...</td>\n",
       "      <td>0.998275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dataset  n_components  \\\n",
       "0        joueurs_ligue1_2024_2025_clean_custom            33   \n",
       "1  joueurs_ligue1_2024_2025_clean_custom_no_GK            34   \n",
       "2         joueurs_ligue1_2024_2025_clean_per90            29   \n",
       "3           joueurs_ligue1_2024_2025_clean_raw            23   \n",
       "\n",
       "   explained_variance_cum  trustworthiness_k  continuity_k    mrre_k  \\\n",
       "0                0.901000           0.997791      0.998450  0.065161   \n",
       "1                0.902434           0.997912      0.998422  0.063516   \n",
       "2                0.900209           0.997883      0.998059  0.067810   \n",
       "3                0.904024           0.997656      0.998129  0.067003   \n",
       "\n",
       "                                            out_file  distance_corr  \n",
       "0  ./reduced_data_pca/joueurs_ligue1_2024_2025_cl...       0.997459  \n",
       "1  ./reduced_data_pca/joueurs_ligue1_2024_2025_cl...       0.997852  \n",
       "2  ./reduced_data_pca/joueurs_ligue1_2024_2025_cl...       0.997254  \n",
       "3  ./reduced_data_pca/joueurs_ligue1_2024_2025_cl...       0.998275  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques sauvegardées -> ./reduced_data_pca/pca_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Sauvegarde & aperçu des métriques\n",
    "if metrics_rows:\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    metrics_df.to_csv(OUT_METRICS_CSV, index=False)\n",
    "    display(metrics_df.head())\n",
    "    print(f\"Métriques sauvegardées -> {OUT_METRICS_CSV}\")\n",
    "else:\n",
    "    print(\"Aucun jeu traité.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
