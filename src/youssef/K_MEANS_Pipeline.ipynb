{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179cfb88",
   "metadata": {},
   "source": [
    "# K-Means Clustering – Multi-Method Pipeline\n",
    "\n",
    "For each dimensionality reduction method (UMAP, PCA, t-SNE, ISOMAP):\n",
    "1) Load the selected embedding (case-insensitive column handling).\n",
    "2) Scale embedding columns with StandardScaler.\n",
    "3) Grid search over n_clusters (e.g., 2–20).\n",
    "4) Compute internal validity metrics:\n",
    "      - Silhouette Score (↑ better)\n",
    "      - Calinski–Harabasz Index (↑ better)\n",
    "      - Davies–Bouldin Index (↓ better)\n",
    "5) Select best config by multi-metric ranking (Silhouette, CH, DB).\n",
    "6) Save grid, best row, clusters, and plots to per-method subfolders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea1f27",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528ea2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874112e0",
   "metadata": {},
   "source": [
    "# Constants and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19da7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REDUCED_ROOT = \"reduced_data\"\n",
    "\n",
    "METHODS = [\"umap\", \"pca\", \"tsne\", \"isomap\"]\n",
    "\n",
    "# Input sub-structure per method\n",
    "UMAP_EMB_DIR = os.path.join(REDUCED_ROOT, \"umap\", \"embeddings\")\n",
    "PCA_EMB_DIR = os.path.join(REDUCED_ROOT, \"pca\", \"embeddings\")\n",
    "TSNE_EMB_DIR = os.path.join(REDUCED_ROOT, \"tsne\", \"embeddings\")\n",
    "ISOMAP_EMB_DIR = os.path.join(REDUCED_ROOT, \"isomap\", \"embeddings\")\n",
    "\n",
    "# Output directories\n",
    "CLUST_ROOT = os.path.join(\"clusters\", \"kmeans\")\n",
    "GRID_DIR = os.path.join(CLUST_ROOT, \"grid_search\")\n",
    "BEST_DIR = os.path.join(CLUST_ROOT, \"best_results\")\n",
    "CLUSTERS_DIR = os.path.join(CLUST_ROOT, \"clusters\")\n",
    "PLOTS_DIR = os.path.join(CLUST_ROOT, \"plots\")\n",
    "\n",
    "for d in [CLUST_ROOT, GRID_DIR, BEST_DIR, CLUSTERS_DIR, PLOTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Grid search parameters\n",
    "N_CLUSTERS_GRID = list(range(3, 13))\n",
    "INIT = \"k-means++\"\n",
    "N_INIT = 20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "METRIC_PRIORITY = [\"silhouette\", \"calinski_harabasz\", \"davies_bouldin\"]\n",
    "\n",
    "KNOWN_ID_COLS = [\n",
    "    \"player_name\", \"equipe\", \"positions\", \"age\",\n",
    "    \"player_id\", \"player_country_code\"\n",
    "]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b415b7d",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd12bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(df: pd.DataFrame, path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"💾 Saved: {path}\")\n",
    "\n",
    "\n",
    "def to_lowercase_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_embedding_columns(df: pd.DataFrame, method_prefix: str) -> list:\n",
    "    pat = re.compile(rf\"^{re.escape(method_prefix)}_?(\\d+)$\")\n",
    "    emb_cols = []\n",
    "    for c in df.columns:\n",
    "        m = pat.match(c)\n",
    "        if m:\n",
    "            emb_cols.append((c, int(m.group(1))))\n",
    "    emb_cols = [name for name, _ in sorted(emb_cols, key=lambda t: t[1])]\n",
    "    return emb_cols\n",
    "\n",
    "\n",
    "def pick_id_columns(df: pd.DataFrame) -> list:\n",
    "    ids = [c for c in KNOWN_ID_COLS if c in df.columns]\n",
    "    if ids:\n",
    "        return ids\n",
    "    non_num = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    return non_num\n",
    "\n",
    "\n",
    "def scale_embedding(X: np.ndarray) -> np.ndarray:\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "def evaluate_labels(X_scaled: np.ndarray, labels: np.ndarray) -> dict:\n",
    "    \"\"\"Compute internal clustering metrics.\"\"\"\n",
    "    n_clusters = len(set(labels))\n",
    "    metrics = {\"silhouette\": np.nan, \"calinski_harabasz\": np.nan, \"davies_bouldin\": np.nan,\n",
    "               \"n_clusters\": int(n_clusters)}\n",
    "\n",
    "    if n_clusters > 1:\n",
    "        try:\n",
    "            sil = silhouette_score(X_scaled, labels)\n",
    "            ch = calinski_harabasz_score(X_scaled, labels)\n",
    "            db = davies_bouldin_score(X_scaled, labels)\n",
    "            metrics.update({\n",
    "                \"silhouette\": float(sil),\n",
    "                \"calinski_harabasz\": float(ch),\n",
    "                \"davies_bouldin\": float(db)\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def select_best_by_metrics(df: pd.DataFrame, priority_list: list[str]) -> pd.Series:\n",
    "    ranked_df = df.copy()\n",
    "    for metric in priority_list:\n",
    "        if metric not in df.columns:\n",
    "            continue\n",
    "        ascending = metric.lower() == \"davies_bouldin\"\n",
    "        ranked_df[f\"{metric}_rank\"] = ranked_df[metric].rank(\n",
    "            method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "        )\n",
    "    rank_cols = [f\"{m}_rank\" for m in priority_list if f\"{m}_rank\" in ranked_df.columns]\n",
    "    ranked_df = ranked_df.sort_values(by=rank_cols, ascending=True)\n",
    "    return ranked_df.iloc[0]\n",
    "\n",
    "\n",
    "def plot_best_scatter(df_full: pd.DataFrame, emb_cols: list, labels_col: str,\n",
    "                      title: str, outpath: str) -> None:\n",
    "    if len(emb_cols) < 2:\n",
    "        print(\"⚠️ Less than 2 embedding dimensions – skipping plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    n_clusters = len(set(df_full[labels_col]))\n",
    "    palette = sns.color_palette(None, max(1, n_clusters))\n",
    "    sns.scatterplot(\n",
    "        data=df_full,\n",
    "        x=emb_cols[0], y=emb_cols[1],\n",
    "        hue=labels_col, palette=palette, s=45, alpha=0.9, edgecolor=\"none\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"📈 Saved plot: {outpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180ea65",
   "metadata": {},
   "source": [
    "# Embedding Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82f2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_embedding_file_for_method(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Resolve the correct embedding file for each dimensionality reduction method\n",
    "    based on dataset naming conventions:\n",
    "      - UMAP  → lowest-MSE embedding (per90 dataset)\n",
    "      - PCA   → embedding containing 'custom'\n",
    "      - t-SNE → embedding containing 'custom_gk'\n",
    "      - ISOMAP→ embedding containing 'raw'\n",
    "    \"\"\"\n",
    "    m = method.lower()\n",
    "\n",
    "    if m == \"umap\":\n",
    "        return select_best_embedding_path(\"umap\")\n",
    "\n",
    "    if m == \"pca\":\n",
    "        pattern = \"*custom*.csv\"\n",
    "        base_dir = PCA_EMB_DIR\n",
    "    elif m == \"tsne\":\n",
    "        pattern = \"*custom_gk*.csv\"\n",
    "        base_dir = TSNE_EMB_DIR\n",
    "    elif m == \"isomap\":\n",
    "        pattern = \"*raw*.csv\"\n",
    "        base_dir = ISOMAP_EMB_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    candidates = sorted(glob.glob(os.path.join(base_dir, pattern)))\n",
    "    if not candidates:\n",
    "        print(f\"⚠️ No embeddings matching {pattern} found for {m.upper()}, using fallback.\")\n",
    "        candidates = sorted(glob.glob(os.path.join(base_dir, \"*.csv\")))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(f\"No embeddings found in {base_dir} for {m.upper()}\")\n",
    "\n",
    "    chosen = candidates[0]\n",
    "    print(f\"✅ Selected {m.upper()} embedding: {os.path.basename(chosen)}\")\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def resolve_all_embedding_files_for_method(method: str) -> list[str]:\n",
    "    m = method.lower()\n",
    "    base_dir = None\n",
    "    if m == \"umap\":\n",
    "        base_dir = UMAP_EMB_DIR\n",
    "    elif m == \"pca\":\n",
    "        base_dir = PCA_EMB_DIR\n",
    "    elif m == \"tsne\":\n",
    "        base_dir = TSNE_EMB_DIR\n",
    "    elif m == \"isomap\":\n",
    "        base_dir = ISOMAP_EMB_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    all_csvs = sorted(glob.glob(os.path.join(base_dir, \"*.csv\")))\n",
    "    print(f\"→ Found {len(all_csvs)} embeddings for {method.upper()} in {base_dir}\")\n",
    "    return all_csvs\n",
    "\n",
    "def select_best_embedding_path(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Select the embedding file corresponding to the lowest MSE\n",
    "    from the best_results folder for the given method.\n",
    "    Falls back to the first embedding if no MSE data is available.\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "    base_best_dir = os.path.join(REDUCED_ROOT, method, \"best_results\")\n",
    "    base_emb_dir = os.path.join(REDUCED_ROOT, method, \"embeddings\")\n",
    "\n",
    "    best_files = glob.glob(os.path.join(base_best_dir, \"*.csv\"))\n",
    "    if not best_files:\n",
    "        print(f\"⚠️ No best_results found for {method.upper()}, using first embedding file instead.\")\n",
    "        all_emb = sorted(glob.glob(os.path.join(base_emb_dir, \"*.csv\")))\n",
    "        if not all_emb:\n",
    "            raise FileNotFoundError(f\"No embeddings found for {method.upper()}.\")\n",
    "        return all_emb[0]\n",
    "\n",
    "    rows = []\n",
    "    for bf in best_files:\n",
    "        try:\n",
    "            dfm = pd.read_csv(bf)\n",
    "            if \"mse\" in dfm.columns and not dfm.empty:\n",
    "                mse = float(dfm[\"mse\"].iloc[0])\n",
    "                rows.append({\"path\": bf, \"mse\": mse})\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"⚠️ No valid MSE entries found for {method.upper()}, using first embedding file.\")\n",
    "        all_emb = sorted(glob.glob(os.path.join(base_emb_dir, \"*.csv\")))\n",
    "        if not all_emb:\n",
    "            raise FileNotFoundError(f\"No embeddings found for {method.upper()}.\")\n",
    "        return all_emb[0]\n",
    "\n",
    "    # Pick lowest-MSE dataset\n",
    "    best_entry = min(rows, key=lambda r: r[\"mse\"])\n",
    "    best_path = best_entry[\"path\"]\n",
    "    tag = os.path.basename(best_path).replace(f\"_{method}_metrics.csv\", \"\")\n",
    "\n",
    "    # Find corresponding embedding\n",
    "    candidates = glob.glob(os.path.join(base_emb_dir, f\"{tag}_*best_embedding*.csv\"))\n",
    "    if not candidates:\n",
    "        candidates = glob.glob(os.path.join(base_emb_dir, f\"{tag}_*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No embedding file found for tag '{tag}' in {base_emb_dir}\")\n",
    "    candidates.sort()\n",
    "    chosen = candidates[0]\n",
    "\n",
    "    print(f\"✅ Selected {method.upper()} embedding with lowest MSE: {os.path.basename(chosen)}\")\n",
    "    return chosen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6942f",
   "metadata": {},
   "source": [
    "# Grid Search for K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb48ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_kmeans_on_embedding(df: pd.DataFrame,\n",
    "                                    emb_cols: list,\n",
    "                                    method: str,\n",
    "                                    tag: str) -> tuple[pd.DataFrame, pd.Series, pd.DataFrame]:\n",
    "    X = df[emb_cols].to_numpy(dtype=float, copy=True)\n",
    "    X_scaled = scale_embedding(X)\n",
    "\n",
    "    rows = []\n",
    "    for n_clust in N_CLUSTERS_GRID:\n",
    "        try:\n",
    "            model = KMeans(\n",
    "                n_clusters=n_clust,\n",
    "                init=INIT,\n",
    "                n_init=N_INIT,\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "            labels = model.fit_predict(X_scaled)\n",
    "            metrics = evaluate_labels(X_scaled, labels)\n",
    "            rows.append({\n",
    "                \"method\": method,\n",
    "                \"tag\": tag,\n",
    "                \"n_clusters_param\": n_clust,\n",
    "                **metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error at n_clusters={n_clust}: {e}\")\n",
    "\n",
    "    grid_df = pd.DataFrame(rows)\n",
    "    best_row = select_best_by_metrics(grid_df, METRIC_PRIORITY)\n",
    "\n",
    "    # Refit best configuration\n",
    "    best_model = KMeans(\n",
    "        n_clusters=int(best_row[\"n_clusters_param\"]),\n",
    "        init=INIT,\n",
    "        n_init=N_INIT,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    best_labels = best_model.fit_predict(X_scaled)\n",
    "    df_best = df.copy()\n",
    "    df_best[\"cluster\"] = best_labels\n",
    "\n",
    "    return grid_df, best_row, df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0d68c",
   "metadata": {},
   "source": [
    "# Orchestration for Single and Multiple Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be559cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_method(method: str) -> None:\n",
    "    \"\"\"\n",
    "    Run K-Means clustering on a representative embedding for a given method.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Processing method: {method.upper()} ===\")\n",
    "\n",
    "    emb_path = resolve_embedding_file_for_method(method)\n",
    "    if not emb_path:\n",
    "        print(f\"⚠️ No embeddings found for {method.upper()}\")\n",
    "        return\n",
    "    tag = os.path.splitext(os.path.basename(emb_path))[0]\n",
    "    print(f\"→ Embedding file: {emb_path}\")\n",
    "\n",
    "    df = pd.read_csv(emb_path)\n",
    "    df = to_lowercase_columns(df)\n",
    "    emb_cols = detect_embedding_columns(df, method)\n",
    "    id_cols = pick_id_columns(df)\n",
    "\n",
    "    grid_df, best_row, df_best = grid_search_kmeans_on_embedding(df, emb_cols, method, tag)\n",
    "\n",
    "    # Paths\n",
    "    grid_out = os.path.join(GRID_DIR, method, f\"{tag}_kmeans_grid.csv\")\n",
    "    best_out = os.path.join(BEST_DIR, method, f\"{tag}_kmeans_best.csv\")\n",
    "    clusters_out = os.path.join(CLUSTERS_DIR, method, f\"{tag}_kmeans_clusters.csv\")\n",
    "    plot_out = os.path.join(PLOTS_DIR, method, f\"{tag}_kmeans_best.png\")\n",
    "    comp_plot = os.path.join(PLOTS_DIR, method, f\"{tag}_positions_per_cluster.png\")\n",
    "\n",
    "    for p in [grid_out, best_out, clusters_out, plot_out, comp_plot]:\n",
    "        os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "    save_csv(grid_df, grid_out)\n",
    "    save_csv(pd.DataFrame([best_row]), best_out)\n",
    "    keep_cols = id_cols + emb_cols + [\"cluster\"]\n",
    "    keep_cols = [c for c in keep_cols if c in df_best.columns]\n",
    "    save_csv(df_best[keep_cols], clusters_out)\n",
    "\n",
    "    title = (f\"{method.upper()} – KMeans Best \"\n",
    "             f\"(n_clusters={int(best_row['n_clusters_param'])})\")\n",
    "    plot_best_scatter(df_best, emb_cols, \"cluster\", title, plot_out)\n",
    "\n",
    "    # Composition plot\n",
    "    try:\n",
    "        if \"positions\" in df_best.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.countplot(\n",
    "                data=df_best,\n",
    "                x=\"cluster\", hue=\"positions\", palette=\"tab10\"\n",
    "            )\n",
    "            plt.title(f\"{method.upper()} – Positions per Cluster\")\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(comp_plot, dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"📊 Saved composition plot: {comp_plot}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not plot composition: {e}\")\n",
    "\n",
    "    print(\"\\n🏆 Best configuration:\")\n",
    "    print(f\"  n_clusters={int(best_row['n_clusters_param'])}\")\n",
    "    print(f\"  silhouette={best_row['silhouette']:.3f} | \"\n",
    "          f\"CH={best_row['calinski_harabasz']:.1f} | \"\n",
    "          f\"DB={best_row['davies_bouldin']:.3f}\")\n",
    "    print(f\"✅ Outputs:\\n\"\n",
    "          f\"    grid → {grid_out}\\n\"\n",
    "          f\"    best → {best_out}\\n\"\n",
    "          f\"    clusters → {clusters_out}\\n\"\n",
    "          f\"    plots → {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbfaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_embeddings_per_method(method: str) -> None:\n",
    "    all_embeddings = resolve_all_embedding_files_for_method(method)\n",
    "    for emb_path in all_embeddings:\n",
    "        try:\n",
    "            tag = os.path.splitext(os.path.basename(emb_path))[0]\n",
    "            print(f\"\\n=== Processing {method.upper()} embedding: {tag} ===\")\n",
    "\n",
    "            df = pd.read_csv(emb_path)\n",
    "            df = to_lowercase_columns(df)\n",
    "            emb_cols = detect_embedding_columns(df, method)\n",
    "            id_cols = pick_id_columns(df)\n",
    "\n",
    "            grid_df, best_row, df_best = grid_search_kmeans_on_embedding(df, emb_cols, method, tag)\n",
    "\n",
    "            # Paths\n",
    "            grid_out = os.path.join(GRID_DIR, method, f\"{tag}_kmeans_grid.csv\")\n",
    "            best_out = os.path.join(BEST_DIR, method, f\"{tag}_kmeans_best.csv\")\n",
    "            clusters_out = os.path.join(CLUSTERS_DIR, method, f\"{tag}_kmeans_clusters.csv\")\n",
    "            plot_out = os.path.join(PLOTS_DIR, method, f\"{tag}_kmeans_best.png\")\n",
    "            comp_plot = os.path.join(PLOTS_DIR, method, f\"{tag}_positions_per_cluster.png\")\n",
    "\n",
    "            for p in [grid_out, best_out, clusters_out, plot_out, comp_plot]:\n",
    "                os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "            save_csv(grid_df, grid_out)\n",
    "            save_csv(pd.DataFrame([best_row]), best_out)\n",
    "            keep_cols = id_cols + emb_cols + [\"cluster\"]\n",
    "            keep_cols = [c for c in keep_cols if c in df_best.columns]\n",
    "            save_csv(df_best[keep_cols], clusters_out)\n",
    "\n",
    "            title = (f\"{method.upper()} – KMeans Best \"\n",
    "                     f\"(n_clusters={int(best_row['n_clusters_param'])})\")\n",
    "            plot_best_scatter(df_best, emb_cols, \"cluster\", title, plot_out)\n",
    "\n",
    "            # Composition plot\n",
    "            try:\n",
    "                if \"positions\" in df_best.columns:\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.countplot(\n",
    "                        data=df_best,\n",
    "                        x=\"cluster\", hue=\"positions\", palette=\"tab10\"\n",
    "                    )\n",
    "                    plt.title(f\"{method.upper()} – Positions per Cluster\")\n",
    "                    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(comp_plot, dpi=300)\n",
    "                    plt.close()\n",
    "                    print(f\"📊 Saved composition plot: {comp_plot}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not plot composition for {tag}: {e}\")\n",
    "\n",
    "            print(\"\\n🏆 Best configuration:\")\n",
    "            print(f\"  n_clusters={int(best_row['n_clusters_param'])}\")\n",
    "            print(f\"  silhouette={best_row['silhouette']:.3f} | \"\n",
    "                  f\"CH={best_row['calinski_harabasz']:.1f} | \"\n",
    "                  f\"DB={best_row['davies_bouldin']:.3f}\")\n",
    "            print(f\"✅ Outputs:\\n\"\n",
    "                  f\"    grid → {grid_out}\\n\"\n",
    "                  f\"    best → {best_out}\\n\"\n",
    "                  f\"    clusters → {clusters_out}\\n\"\n",
    "                  f\"    plots → {plot_out}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping embedding {emb_path} due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9a1cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning reduced embeddings under: reduced_data\n",
      "\n",
      "=== Processing method: UMAP ===\n",
      "✅ Selected UMAP embedding with lowest MSE: joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding.csv\n",
      "→ Embedding file: reduced_data\\umap\\embeddings\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding.csv\n",
      "💾 Saved: clusters\\kmeans\\grid_search\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_grid.csv\n",
      "💾 Saved: clusters\\kmeans\\best_results\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_best.csv\n",
      "💾 Saved: clusters\\kmeans\\clusters\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_clusters.csv\n",
      "📈 Saved plot: clusters\\kmeans\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_best.png\n",
      "📊 Saved composition plot: clusters\\kmeans\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_positions_per_cluster.png\n",
      "\n",
      "🏆 Best configuration:\n",
      "  n_clusters=5\n",
      "  silhouette=0.355 | CH=231.1 | DB=0.993\n",
      "✅ Outputs:\n",
      "    grid → clusters\\kmeans\\grid_search\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_grid.csv\n",
      "    best → clusters\\kmeans\\best_results\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_best.csv\n",
      "    clusters → clusters\\kmeans\\clusters\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_clusters.csv\n",
      "    plots → clusters\\kmeans\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_kmeans_best.png\n",
      "\n",
      "=== Processing method: PCA ===\n",
      "✅ Selected PCA embedding: joueurs_ligue1_PCA_custom.csv\n",
      "→ Embedding file: reduced_data\\pca\\embeddings\\joueurs_ligue1_PCA_custom.csv\n",
      "💾 Saved: clusters\\kmeans\\grid_search\\pca\\joueurs_ligue1_PCA_custom_kmeans_grid.csv\n",
      "💾 Saved: clusters\\kmeans\\best_results\\pca\\joueurs_ligue1_PCA_custom_kmeans_best.csv\n",
      "💾 Saved: clusters\\kmeans\\clusters\\pca\\joueurs_ligue1_PCA_custom_kmeans_clusters.csv\n",
      "📈 Saved plot: clusters\\kmeans\\plots\\pca\\joueurs_ligue1_PCA_custom_kmeans_best.png\n",
      "📊 Saved composition plot: clusters\\kmeans\\plots\\pca\\joueurs_ligue1_PCA_custom_positions_per_cluster.png\n",
      "\n",
      "🏆 Best configuration:\n",
      "  n_clusters=6\n",
      "  silhouette=0.059 | CH=7.0 | DB=3.553\n",
      "✅ Outputs:\n",
      "    grid → clusters\\kmeans\\grid_search\\pca\\joueurs_ligue1_PCA_custom_kmeans_grid.csv\n",
      "    best → clusters\\kmeans\\best_results\\pca\\joueurs_ligue1_PCA_custom_kmeans_best.csv\n",
      "    clusters → clusters\\kmeans\\clusters\\pca\\joueurs_ligue1_PCA_custom_kmeans_clusters.csv\n",
      "    plots → clusters\\kmeans\\plots\\pca\\joueurs_ligue1_PCA_custom_kmeans_best.png\n",
      "\n",
      "=== Processing method: TSNE ===\n",
      "✅ Selected TSNE embedding: joueurs_ligue1_tSNE_custom_GK.csv\n",
      "→ Embedding file: reduced_data\\tsne\\embeddings\\joueurs_ligue1_tSNE_custom_GK.csv\n",
      "💾 Saved: clusters\\kmeans\\grid_search\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_grid.csv\n",
      "💾 Saved: clusters\\kmeans\\best_results\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_best.csv\n",
      "💾 Saved: clusters\\kmeans\\clusters\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_clusters.csv\n",
      "📈 Saved plot: clusters\\kmeans\\plots\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_best.png\n",
      "📊 Saved composition plot: clusters\\kmeans\\plots\\tsne\\joueurs_ligue1_tSNE_custom_GK_positions_per_cluster.png\n",
      "\n",
      "🏆 Best configuration:\n",
      "  n_clusters=7\n",
      "  silhouette=0.372 | CH=258.8 | DB=0.960\n",
      "✅ Outputs:\n",
      "    grid → clusters\\kmeans\\grid_search\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_grid.csv\n",
      "    best → clusters\\kmeans\\best_results\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_best.csv\n",
      "    clusters → clusters\\kmeans\\clusters\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_clusters.csv\n",
      "    plots → clusters\\kmeans\\plots\\tsne\\joueurs_ligue1_tSNE_custom_GK_kmeans_best.png\n",
      "\n",
      "=== Processing method: ISOMAP ===\n",
      "✅ Selected ISOMAP embedding: joueurs_ligue1_ISOMap_raw.csv\n",
      "→ Embedding file: reduced_data\\isomap\\embeddings\\joueurs_ligue1_ISOMap_raw.csv\n",
      "💾 Saved: clusters\\kmeans\\grid_search\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_grid.csv\n",
      "💾 Saved: clusters\\kmeans\\best_results\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_best.csv\n",
      "💾 Saved: clusters\\kmeans\\clusters\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_clusters.csv\n",
      "📈 Saved plot: clusters\\kmeans\\plots\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_best.png\n",
      "📊 Saved composition plot: clusters\\kmeans\\plots\\isomap\\joueurs_ligue1_ISOMap_raw_positions_per_cluster.png\n",
      "\n",
      "🏆 Best configuration:\n",
      "  n_clusters=6\n",
      "  silhouette=0.313 | CH=86.9 | DB=1.090\n",
      "✅ Outputs:\n",
      "    grid → clusters\\kmeans\\grid_search\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_grid.csv\n",
      "    best → clusters\\kmeans\\best_results\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_best.csv\n",
      "    clusters → clusters\\kmeans\\clusters\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_clusters.csv\n",
      "    plots → clusters\\kmeans\\plots\\isomap\\joueurs_ligue1_ISOMap_raw_kmeans_best.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Scanning reduced embeddings under: {REDUCED_ROOT}\")\n",
    "for method in METHODS:\n",
    "    try:\n",
    "        process_method(method)        \n",
    "        # process_all_embeddings_per_method(method)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Skipping {method.upper()} due to error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
