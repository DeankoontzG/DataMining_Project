{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011890b6",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering ‚Äì Multi-Method Pipeline\n",
    "\n",
    "For each method, we:\n",
    "1) Load the selected embedding (case-insensitive column handling).\n",
    "2) Scale the embedding columns (StandardScaler).\n",
    "3) Grid search Agglomerative Clustering over (n_clusters, linkage).\n",
    "4) Compute internal validity metrics:\n",
    "      - Silhouette (‚Üë better)\n",
    "      - Calinski‚ÄìHarabasz (‚Üë better)\n",
    "      - Davies‚ÄìBouldin (‚Üì better)\n",
    "5) Select the best config by: Silhouette ‚Üë, then CH ‚Üë, then DB ‚Üì.\n",
    "6) Save grid, best row, cluster assignments, and a plot of the best solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4fdc3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "604439c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c5fc6",
   "metadata": {},
   "source": [
    "# Constants and Directory Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ef1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCED_ROOT = \"reduced_data\"\n",
    "\n",
    "METHODS = [\"umap\", \"pca\", \"tsne\", \"isomap\"]\n",
    "\n",
    "UMAP_DIR = os.path.join(REDUCED_ROOT, \"umap\")\n",
    "UMAP_EMB_DIR = os.path.join(UMAP_DIR, \"embeddings\")\n",
    "UMAP_BEST_DIR = os.path.join(UMAP_DIR, \"best_results\")\n",
    "\n",
    "PCA_EMB_DIR = os.path.join(REDUCED_ROOT, \"pca\", \"embeddings\")\n",
    "TSNE_EMB_DIR = os.path.join(REDUCED_ROOT, \"tsne\", \"embeddings\")\n",
    "ISOMAP_EMB_DIR = os.path.join(REDUCED_ROOT, \"isomap\", \"embeddings\")\n",
    "\n",
    "CLUST_ROOT = os.path.join(\"clusters\", \"agglomerative_clustering\")\n",
    "GRID_DIR = os.path.join(CLUST_ROOT, \"grid_search\")\n",
    "BEST_DIR = os.path.join(CLUST_ROOT, \"best_results\")\n",
    "CLUSTERS_DIR = os.path.join(CLUST_ROOT, \"clusters\")\n",
    "PLOTS_DIR = os.path.join(CLUST_ROOT, \"plots\")\n",
    "\n",
    "for d in [CLUST_ROOT, GRID_DIR, BEST_DIR, CLUSTERS_DIR, PLOTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "# N_CLUSTERS_GRID = list(range(2, 11))\n",
    "N_CLUSTERS_GRID = list(range(3, 11))\n",
    "LINKAGE_METHODS = [\"ward\", \"complete\", \"average\"]\n",
    "METRIC_PRIORITY = [\"silhouette\", \"calinski_harabasz\", \"davies_bouldin\"]\n",
    "\n",
    "KNOWN_ID_COLS = [\n",
    "    \"player_name\", \"equipe\", \"positions\", \"age\",\n",
    "    \"player_id\", \"player_country_code\"\n",
    "]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb05423",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b122648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(df: pd.DataFrame, path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"üíæ Saved: {path}\")\n",
    "\n",
    "def to_lowercase_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def detect_embedding_columns(df: pd.DataFrame, method_prefix: str) -> list:\n",
    "    pat = re.compile(rf\"^{re.escape(method_prefix)}_?(\\d+)$\")\n",
    "    emb_cols = []\n",
    "    for c in df.columns:\n",
    "        m = pat.match(c)\n",
    "        if m:\n",
    "            emb_cols.append((c, int(m.group(1))))\n",
    "    emb_cols = [name for name, _ in sorted(emb_cols, key=lambda t: t[1])]\n",
    "    return emb_cols\n",
    "\n",
    "def pick_id_columns(df: pd.DataFrame) -> list:\n",
    "    ids = [c for c in KNOWN_ID_COLS if c in df.columns]\n",
    "    if ids:\n",
    "        return ids\n",
    "    non_num = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    return non_num\n",
    "\n",
    "def scale_embedding(X: np.ndarray) -> np.ndarray:\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "def evaluate_labels(X_scaled: np.ndarray, labels: np.ndarray) -> dict:\n",
    "    \"\"\"Compute clustering quality metrics.\"\"\"\n",
    "    n_clusters = len(set(labels))\n",
    "    metrics = {\"silhouette\": np.nan, \"calinski_harabasz\": np.nan, \"davies_bouldin\": np.nan,\n",
    "               \"n_clusters\": int(n_clusters)}\n",
    "\n",
    "    if n_clusters > 1:\n",
    "        try:\n",
    "            sil = silhouette_score(X_scaled, labels)\n",
    "            ch = calinski_harabasz_score(X_scaled, labels)\n",
    "            db = davies_bouldin_score(X_scaled, labels)\n",
    "            metrics.update({\n",
    "                \"silhouette\": float(sil),\n",
    "                \"calinski_harabasz\": float(ch),\n",
    "                \"davies_bouldin\": float(db)\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def select_best_by_metrics(df: pd.DataFrame, priority_list: list[str]) -> pd.Series:\n",
    "    ranked_df = df.copy()\n",
    "    for metric in priority_list:\n",
    "        if metric not in df.columns:\n",
    "            continue\n",
    "        ascending = metric.lower() == 'davies_bouldin'\n",
    "        ranked_df[f\"{metric}_rank\"] = ranked_df[metric].rank(\n",
    "            method=\"min\", ascending=ascending, na_option=\"bottom\"\n",
    "        )\n",
    "\n",
    "    rank_cols = [f\"{m}_rank\" for m in priority_list if f\"{m}_rank\" in ranked_df.columns]\n",
    "    ranked_df = ranked_df.sort_values(by=rank_cols, ascending=True)\n",
    "    return ranked_df.iloc[0]\n",
    "\n",
    "def plot_best_scatter(df_full: pd.DataFrame, emb_cols: list, labels_col: str,\n",
    "                      title: str, outpath: str) -> None:\n",
    "    if len(emb_cols) < 2:\n",
    "        print(\"‚ö†Ô∏è Less than 2 embedding dimensions ‚Äì skipping plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    n_clusters = len(set(df_full[labels_col]))\n",
    "    palette = sns.color_palette(None, max(1, n_clusters))\n",
    "    sns.scatterplot(\n",
    "        data=df_full,\n",
    "        x=emb_cols[0], y=emb_cols[1],\n",
    "        hue=labels_col, palette=palette, s=45, alpha=0.9, edgecolor=\"none\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"üìà Saved plot: {outpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac2e38",
   "metadata": {},
   "source": [
    "# Embedding Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b85baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_one_csv_from_dir_by_method(emb_dir: str, method_keyword: str) -> str:\n",
    "    if not os.path.isdir(emb_dir):\n",
    "        raise FileNotFoundError(f\"Embeddings directory not found: {emb_dir}\")\n",
    "\n",
    "    all_csv = glob.glob(os.path.join(emb_dir, \"*.csv\"))\n",
    "    cand = [p for p in all_csv if method_keyword.lower() in os.path.basename(p).lower()]\n",
    "    if not cand:\n",
    "        cand = all_csv.copy()\n",
    "    cand.sort()\n",
    "    return cand[0]\n",
    "\n",
    "def resolve_all_embedding_files_for_method(method: str) -> list[str]:\n",
    "    m = method.lower()\n",
    "    base_dir = None\n",
    "    if m == \"umap\":\n",
    "        base_dir = UMAP_EMB_DIR\n",
    "    elif m == \"pca\":\n",
    "        base_dir = PCA_EMB_DIR\n",
    "    elif m == \"tsne\":\n",
    "        base_dir = TSNE_EMB_DIR\n",
    "    elif m == \"isomap\":\n",
    "        base_dir = ISOMAP_EMB_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    all_csvs = sorted(glob.glob(os.path.join(base_dir, \"*.csv\")))\n",
    "    print(f\"‚Üí Found {len(all_csvs)} embeddings for {method.upper()} in {base_dir}\")\n",
    "    return all_csvs\n",
    "\n",
    "def select_best_embedding_path(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Select the embedding file corresponding to the lowest MSE\n",
    "    from the best_results folder for the given method.\n",
    "    Falls back to the first embedding if no MSE data is available.\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "    base_best_dir = os.path.join(REDUCED_ROOT, method, \"best_results\")\n",
    "    base_emb_dir = os.path.join(REDUCED_ROOT, method, \"embeddings\")\n",
    "\n",
    "    best_files = glob.glob(os.path.join(base_best_dir, \"*.csv\"))\n",
    "    if not best_files:\n",
    "        print(f\"‚ö†Ô∏è No best_results found for {method.upper()}, using first embedding instead.\")\n",
    "        all_emb = sorted(glob.glob(os.path.join(base_emb_dir, \"*.csv\")))\n",
    "        if not all_emb:\n",
    "            raise FileNotFoundError(f\"No embeddings found for {method.upper()}.\")\n",
    "        return all_emb[0]\n",
    "\n",
    "    rows = []\n",
    "    for bf in best_files:\n",
    "        try:\n",
    "            dfm = pd.read_csv(bf)\n",
    "            if \"mse\" in dfm.columns and not dfm.empty:\n",
    "                mse = float(dfm[\"mse\"].iloc[0])\n",
    "                rows.append({\"path\": bf, \"mse\": mse})\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"‚ö†Ô∏è No valid MSE entries found for {method.upper()}, using first embedding file.\")\n",
    "        all_emb = sorted(glob.glob(os.path.join(base_emb_dir, \"*.csv\")))\n",
    "        if not all_emb:\n",
    "            raise FileNotFoundError(f\"No embeddings found for {method.upper()}.\")\n",
    "        return all_emb[0]\n",
    "\n",
    "    # Pick the dataset with the lowest MSE\n",
    "    best_entry = min(rows, key=lambda r: r[\"mse\"])\n",
    "    best_path = best_entry[\"path\"]\n",
    "    tag = os.path.basename(best_path).replace(f\"_{method}_metrics.csv\", \"\")\n",
    "\n",
    "    # Locate corresponding embedding\n",
    "    candidates = glob.glob(os.path.join(base_emb_dir, f\"{tag}_*best_embedding*.csv\"))\n",
    "    if not candidates:\n",
    "        candidates = glob.glob(os.path.join(base_emb_dir, f\"{tag}_*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No embedding found for tag '{tag}' in {base_emb_dir}\")\n",
    "\n",
    "    candidates.sort()\n",
    "    chosen = candidates[0]\n",
    "    print(f\"‚úÖ Selected {method.upper()} embedding with lowest MSE: {os.path.basename(chosen)}\")\n",
    "    return chosen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69995399",
   "metadata": {},
   "source": [
    "# Grid Search for Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09e5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_agglomerative_on_embedding(df: pd.DataFrame,\n",
    "                                           emb_cols: list,\n",
    "                                           method: str,\n",
    "                                           tag: str) -> tuple[pd.DataFrame, pd.Series, pd.DataFrame]:\n",
    "    X = df[emb_cols].to_numpy(dtype=float, copy=True)\n",
    "    X_scaled = scale_embedding(X)\n",
    "\n",
    "    rows = []\n",
    "    for n_clust in N_CLUSTERS_GRID:\n",
    "        for link in LINKAGE_METHODS:\n",
    "            try:\n",
    "                model = AgglomerativeClustering(\n",
    "                    n_clusters=n_clust,\n",
    "                    linkage=link\n",
    "                )\n",
    "                labels = model.fit_predict(X_scaled)\n",
    "                metrics = evaluate_labels(X_scaled, labels)\n",
    "                rows.append({\n",
    "                    \"method\": method,\n",
    "                    \"tag\": tag,\n",
    "                    \"n_clusters_param\": n_clust,\n",
    "                    \"linkage\": link,\n",
    "                    **metrics\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error with linkage={link}, n_clusters={n_clust}: {e}\")\n",
    "\n",
    "    grid_df = pd.DataFrame(rows)\n",
    "    best_row = select_best_by_metrics(grid_df, METRIC_PRIORITY)\n",
    "\n",
    "    # Refit best configuration\n",
    "    best_model = AgglomerativeClustering(\n",
    "        n_clusters=int(best_row[\"n_clusters_param\"]),\n",
    "        linkage=best_row[\"linkage\"]\n",
    "    )\n",
    "    best_labels = best_model.fit_predict(X_scaled)\n",
    "    df_best = df.copy()\n",
    "    df_best[\"cluster\"] = best_labels\n",
    "\n",
    "    return grid_df, best_row, df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec18ae9",
   "metadata": {},
   "source": [
    "# Orchestration for All Methods / Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc27043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_method(method: str) -> None:\n",
    "    \"\"\"\n",
    "    Resolve the single embedding to use, run Agglomerative grid search, select best model,\n",
    "    and save grid, best, clusters, and plot.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Processing method: {method.upper()} ===\")\n",
    "\n",
    "    # --- Select the embedding with lowest MSE (fallback to first if not found) ---\n",
    "    try:\n",
    "        emb_path = select_best_embedding_path(method)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not select best embedding for {method.upper()}: {e}\")\n",
    "        return\n",
    "\n",
    "    tag = os.path.splitext(os.path.basename(emb_path))[0]\n",
    "    print(f\"‚Üí Embedding file: {emb_path}\")\n",
    "\n",
    "    # Load & prepare data\n",
    "    df = pd.read_csv(emb_path)\n",
    "    df = to_lowercase_columns(df)\n",
    "    emb_cols = detect_embedding_columns(df, method)\n",
    "    id_cols = pick_id_columns(df)\n",
    "    print(f\"Detected embedding columns ({len(emb_cols)}): {emb_cols[:8]}{' ...' if len(emb_cols) > 8 else ''}\")\n",
    "    print(f\"ID columns retained: {id_cols}\")\n",
    "\n",
    "    # --- Grid search ---\n",
    "    grid_df, best_row, df_best = grid_search_agglomerative_on_embedding(df, emb_cols, method, tag)\n",
    "\n",
    "    # --- Define paths ---\n",
    "    grid_out = os.path.join(GRID_DIR, method, f\"{tag}_agglo_grid.csv\")\n",
    "    best_out = os.path.join(BEST_DIR, method, f\"{tag}_agglo_best.csv\")\n",
    "    clusters_out = os.path.join(CLUSTERS_DIR, method, f\"{tag}_agglo_clusters.csv\")\n",
    "    plot_out = os.path.join(PLOTS_DIR, method, f\"{tag}_agglo_best.png\")\n",
    "    comp_plot = os.path.join(PLOTS_DIR, method, f\"{tag}_positions_per_cluster.png\")\n",
    "\n",
    "    # --- Ensure directories exist BEFORE saving ---\n",
    "    for p in [grid_out, best_out, clusters_out, plot_out, comp_plot]:\n",
    "        os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "    # --- Save outputs ---\n",
    "    save_csv(grid_df, grid_out)\n",
    "    save_csv(pd.DataFrame([best_row]), best_out)\n",
    "    keep_cols = id_cols + emb_cols + [\"cluster\"]\n",
    "    keep_cols = [c for c in keep_cols if c in df_best.columns]\n",
    "    save_csv(df_best[keep_cols], clusters_out)\n",
    "\n",
    "    # --- Plot clusters ---\n",
    "    title = (f\"{method.upper()} ‚Äì Agglomerative Best \"\n",
    "             f\"(n_clusters={int(best_row['n_clusters_param'])}, linkage={best_row['linkage']})\")\n",
    "    plot_best_scatter(df_best, emb_cols, \"cluster\", title, plot_out)\n",
    "\n",
    "    # --- Optional composition plot ---\n",
    "    try:\n",
    "        if \"positions\" in df_best.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.countplot(\n",
    "                data=df_best,\n",
    "                x=\"cluster\", hue=\"positions\", palette=\"tab10\"\n",
    "            )\n",
    "            plt.title(f\"{method.upper()} ‚Äì Positions per Cluster\")\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(comp_plot, dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"üìä Saved composition plot: {comp_plot}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not plot composition: {e}\")\n",
    "\n",
    "    # --- Console summary ---\n",
    "    print(\"\\nüèÜ Best configuration:\")\n",
    "    print(f\"  n_clusters={int(best_row['n_clusters_param'])} | linkage={best_row['linkage']}\")\n",
    "    print(f\"  silhouette={best_row['silhouette']:.3f} | \"\n",
    "          f\"CH={best_row['calinski_harabasz']:.1f} | \"\n",
    "          f\"DB={best_row['davies_bouldin']:.3f}\")\n",
    "    print(f\"‚úÖ Outputs:\\n\"\n",
    "          f\"    grid ‚Üí {grid_out}\\n\"\n",
    "          f\"    best ‚Üí {best_out}\\n\"\n",
    "          f\"    clusters ‚Üí {clusters_out}\\n\"\n",
    "          f\"    plots ‚Üí {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79890a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_embeddings_per_method(method: str) -> None:\n",
    "    all_embeddings = resolve_all_embedding_files_for_method(method)\n",
    "    for emb_path in all_embeddings:\n",
    "        try:\n",
    "            tag = os.path.splitext(os.path.basename(emb_path))[0]\n",
    "            print(f\"\\n=== Processing {method.upper()} embedding: {tag} ===\")\n",
    "\n",
    "            df = pd.read_csv(emb_path)\n",
    "            df = to_lowercase_columns(df)\n",
    "            emb_cols = detect_embedding_columns(df, method)\n",
    "            id_cols = pick_id_columns(df)\n",
    "\n",
    "            print(f\"Detected embedding columns ({len(emb_cols)}): {emb_cols[:8]}{' ...' if len(emb_cols) > 8 else ''}\")\n",
    "            print(f\"ID columns retained: {id_cols}\")\n",
    "\n",
    "            grid_df, best_row, df_best = grid_search_agglomerative_on_embedding(df, emb_cols, method, tag)\n",
    "\n",
    "            grid_out = os.path.join(GRID_DIR, method, f\"{tag}_agglo_grid.csv\")\n",
    "            best_out = os.path.join(BEST_DIR, method, f\"{tag}_agglo_best.csv\")\n",
    "            clusters_out = os.path.join(CLUSTERS_DIR, method, f\"{tag}_agglo_clusters.csv\")\n",
    "            plot_out = os.path.join(PLOTS_DIR, method, f\"{tag}_agglo_best.png\")\n",
    "            comp_plot = os.path.join(PLOTS_DIR, method, f\"{tag}_positions_per_cluster.png\")\n",
    "\n",
    "            for p in [grid_out, best_out, clusters_out, plot_out, comp_plot]:\n",
    "                os.makedirs(os.path.dirname(p), exist_ok=True)\n",
    "\n",
    "            # --- Save results ---\n",
    "            save_csv(grid_df, grid_out)\n",
    "            save_csv(pd.DataFrame([best_row]), best_out)\n",
    "            keep_cols = id_cols + emb_cols + [\"cluster\"]\n",
    "            keep_cols = [c for c in keep_cols if c in df_best.columns]\n",
    "            save_csv(df_best[keep_cols], clusters_out)\n",
    "\n",
    "            # --- Plot scatter ---\n",
    "            title = (f\"{method.upper()} ‚Äì Agglomerative Best \"\n",
    "                    f\"(n_clusters={int(best_row['n_clusters_param'])}, linkage={best_row['linkage']})\")\n",
    "            plot_best_scatter(df_best, emb_cols, \"cluster\", title, plot_out)\n",
    "\n",
    "            # Optional composition plot by position\n",
    "            try:\n",
    "                if \"positions\" in df_best.columns:\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.countplot(\n",
    "                        data=df_best,\n",
    "                        x=\"cluster\", hue=\"positions\", palette=\"tab10\"\n",
    "                    )\n",
    "                    plt.title(f\"{method.upper()} ‚Äì Positions per Cluster\")\n",
    "                    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(comp_plot, dpi=300)\n",
    "                    plt.close()\n",
    "                    print(f\"üìä Saved composition plot: {comp_plot}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not plot composition for {tag}: {e}\")\n",
    "\n",
    "            print(\"\\nüèÜ Best configuration:\")\n",
    "            print(f\"  n_clusters={int(best_row['n_clusters_param'])} | linkage={best_row['linkage']}\")\n",
    "            print(f\"  silhouette={best_row['silhouette']:.3f} | \"\n",
    "                    f\"CH={best_row['calinski_harabasz']:.1f} | \"\n",
    "                    f\"DB={best_row['davies_bouldin']:.3f}\")\n",
    "            print(f\"‚úÖ Outputs:\\n\"\n",
    "                    f\"    grid ‚Üí {grid_out}\\n\"\n",
    "                    f\"    best ‚Üí {best_out}\\n\"\n",
    "                    f\"    clusters ‚Üí {clusters_out}\\n\"\n",
    "                    f\"    plot ‚Üí {plot_out}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping embedding {emb_path} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef13c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning reduced embeddings under: reduced_data\n",
      "\n",
      "=== Processing method: UMAP ===\n",
      "‚úÖ Selected UMAP embedding with lowest MSE: joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding.csv\n",
      "‚Üí Embedding file: reduced_data\\umap\\embeddings\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding.csv\n",
      "Detected embedding columns (5): ['umap_1', 'umap_2', 'umap_3', 'umap_4', 'umap_5']\n",
      "ID columns retained: ['player_name', 'equipe', 'positions', 'age', 'player_id', 'player_country_code']\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\grid_search\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_grid.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\best_results\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_best.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\clusters\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_clusters.csv\n",
      "üìà Saved plot: clusters\\agglomerative_clustering\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_best.png\n",
      "üìä Saved composition plot: clusters\\agglomerative_clustering\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_positions_per_cluster.png\n",
      "\n",
      "üèÜ Best configuration:\n",
      "  n_clusters=5 | linkage=ward\n",
      "  silhouette=0.333 | CH=216.0 | DB=1.086\n",
      "‚úÖ Outputs:\n",
      "    grid ‚Üí clusters\\agglomerative_clustering\\grid_search\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_grid.csv\n",
      "    best ‚Üí clusters\\agglomerative_clustering\\best_results\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_best.csv\n",
      "    clusters ‚Üí clusters\\agglomerative_clustering\\clusters\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_clusters.csv\n",
      "    plots ‚Üí clusters\\agglomerative_clustering\\plots\\umap\\joueurs_ligue1_2024_2025_clean_per90_umap5d_best_embedding_agglo_best.png\n",
      "\n",
      "=== Processing method: PCA ===\n",
      "‚ö†Ô∏è No best_results found for PCA, using first embedding instead.\n",
      "‚Üí Embedding file: reduced_data\\pca\\embeddings\\joueurs_ligue1_PCA_custom.csv\n",
      "Detected embedding columns (34): ['pca1', 'pca2', 'pca3', 'pca4', 'pca5', 'pca6', 'pca7', 'pca8'] ...\n",
      "ID columns retained: ['player_name', 'equipe', 'positions']\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\grid_search\\pca\\joueurs_ligue1_PCA_custom_agglo_grid.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\best_results\\pca\\joueurs_ligue1_PCA_custom_agglo_best.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\clusters\\pca\\joueurs_ligue1_PCA_custom_agglo_clusters.csv\n",
      "üìà Saved plot: clusters\\agglomerative_clustering\\plots\\pca\\joueurs_ligue1_PCA_custom_agglo_best.png\n",
      "üìä Saved composition plot: clusters\\agglomerative_clustering\\plots\\pca\\joueurs_ligue1_PCA_custom_positions_per_cluster.png\n",
      "\n",
      "üèÜ Best configuration:\n",
      "  n_clusters=3 | linkage=complete\n",
      "  silhouette=0.381 | CH=5.8 | DB=0.437\n",
      "‚úÖ Outputs:\n",
      "    grid ‚Üí clusters\\agglomerative_clustering\\grid_search\\pca\\joueurs_ligue1_PCA_custom_agglo_grid.csv\n",
      "    best ‚Üí clusters\\agglomerative_clustering\\best_results\\pca\\joueurs_ligue1_PCA_custom_agglo_best.csv\n",
      "    clusters ‚Üí clusters\\agglomerative_clustering\\clusters\\pca\\joueurs_ligue1_PCA_custom_agglo_clusters.csv\n",
      "    plots ‚Üí clusters\\agglomerative_clustering\\plots\\pca\\joueurs_ligue1_PCA_custom_agglo_best.png\n",
      "\n",
      "=== Processing method: TSNE ===\n",
      "‚ö†Ô∏è No best_results found for TSNE, using first embedding instead.\n",
      "‚Üí Embedding file: reduced_data\\tsne\\embeddings\\joueurs_ligue1_tSNE_custom.csv\n",
      "Detected embedding columns (4): ['tsne_1', 'tsne_2', 'tsne_3', 'tsne_4']\n",
      "ID columns retained: ['player_name', 'equipe', 'positions']\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\grid_search\\tsne\\joueurs_ligue1_tSNE_custom_agglo_grid.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\best_results\\tsne\\joueurs_ligue1_tSNE_custom_agglo_best.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\clusters\\tsne\\joueurs_ligue1_tSNE_custom_agglo_clusters.csv\n",
      "üìà Saved plot: clusters\\agglomerative_clustering\\plots\\tsne\\joueurs_ligue1_tSNE_custom_agglo_best.png\n",
      "üìä Saved composition plot: clusters\\agglomerative_clustering\\plots\\tsne\\joueurs_ligue1_tSNE_custom_positions_per_cluster.png\n",
      "\n",
      "üèÜ Best configuration:\n",
      "  n_clusters=3 | linkage=complete\n",
      "  silhouette=0.271 | CH=139.7 | DB=1.272\n",
      "‚úÖ Outputs:\n",
      "    grid ‚Üí clusters\\agglomerative_clustering\\grid_search\\tsne\\joueurs_ligue1_tSNE_custom_agglo_grid.csv\n",
      "    best ‚Üí clusters\\agglomerative_clustering\\best_results\\tsne\\joueurs_ligue1_tSNE_custom_agglo_best.csv\n",
      "    clusters ‚Üí clusters\\agglomerative_clustering\\clusters\\tsne\\joueurs_ligue1_tSNE_custom_agglo_clusters.csv\n",
      "    plots ‚Üí clusters\\agglomerative_clustering\\plots\\tsne\\joueurs_ligue1_tSNE_custom_agglo_best.png\n",
      "\n",
      "=== Processing method: ISOMAP ===\n",
      "‚ö†Ô∏è No best_results found for ISOMAP, using first embedding instead.\n",
      "‚Üí Embedding file: reduced_data\\isomap\\embeddings\\joueurs_ligue1_ISOMap_custom.csv\n",
      "Detected embedding columns (6): ['isomap_1', 'isomap_2', 'isomap_3', 'isomap_4', 'isomap_5', 'isomap_6']\n",
      "ID columns retained: ['player_name', 'equipe', 'positions']\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\grid_search\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_grid.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\best_results\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_best.csv\n",
      "üíæ Saved: clusters\\agglomerative_clustering\\clusters\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_clusters.csv\n",
      "üìà Saved plot: clusters\\agglomerative_clustering\\plots\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_best.png\n",
      "üìä Saved composition plot: clusters\\agglomerative_clustering\\plots\\isomap\\joueurs_ligue1_ISOMap_custom_positions_per_cluster.png\n",
      "\n",
      "üèÜ Best configuration:\n",
      "  n_clusters=3 | linkage=average\n",
      "  silhouette=0.272 | CH=15.1 | DB=1.051\n",
      "‚úÖ Outputs:\n",
      "    grid ‚Üí clusters\\agglomerative_clustering\\grid_search\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_grid.csv\n",
      "    best ‚Üí clusters\\agglomerative_clustering\\best_results\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_best.csv\n",
      "    clusters ‚Üí clusters\\agglomerative_clustering\\clusters\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_clusters.csv\n",
      "    plots ‚Üí clusters\\agglomerative_clustering\\plots\\isomap\\joueurs_ligue1_ISOMap_custom_agglo_best.png\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scanning reduced embeddings under: {REDUCED_ROOT}\")\n",
    "for method in METHODS:\n",
    "    try:\n",
    "        process_method(method)\n",
    "        # process_all_embeddings_per_method(method)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Skipping method {method.upper()} due to error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
