Projet de Rémy Cazabet :
https://cazabetremy.fr/Teaching/DSIA/DM.html

Lien vers l'API : https://fbrapi.com/documentation#team-season-stats
Lien vers la source de données : https://fbref.com/en/comps/13/stats/Ligue-1-Stats

# Répartitiondu travail

feature engeeniring : netoyer les données pour ses problématiques.

tester plusieurs methodes pour selectionner les colonnes : PCA (moi), t-SNE (Guilhem), UMAP (Youssef)

Choisir quelle methodes de clusterings utiliser et en faire une chacun : (DBScan, Agglomerative Clustering) : youssef, (Gaussian Mixture, affinity propagation) : guillhem, (BIRCH, ward) :artus

---

- Chacun utilise les jeux de donnees `(joueurs_ligue1_2024_2025_clean_per90.csv` et `joueurs_ligue1_2024_2025_clean_raw.csv`) pour faire la dimension reduction et du coup créer des "jeux de donnees reduits" associes a chaque methode de reduction de dimension (PCA, t-SNE, UMAP et ISOMap).
- Pour le clustering on applique les differentes methodes sur les jeux de donnees reduits.


OBJECTIF RAPPORT : 
1 . Comparaison des méthodes de dim reduction : 
Métriques :
- Trustworthiness. Mesure à quel point les voisins proches dans l’espace réduit étaient aussi voisins dans l’espace d’origine. [0;1], plus c'est grand mieux c'est. sklearn.manifold.trustworthiness
- Continuity, L’inverse du "trustworthiness" : est-ce que les vrais voisins (dans l’espace original) ont été préservés dans l’espace réduit ? Complémentaire askip
- distance_correlation: correlation of distances between spaces (-1 to 1)
- Mean Relative Rank Error (MRRE) : Moyenne de l’écart de rang entre les voisins dans les deux espaces.

2 . Comparaison des méthodes de clustering : 
Métriques de comparaison : 
- Silouhette score [-1,1]. Plus c'est grand mieux c'est, mesure la compacité et la séparation des clusters.
- Davies-Bouldin Index. Plus c’est faible, mieux c’est (mesure la similarité intra/inter-cluster).
- Calinski-Harabasz Index. Plus c’est élevé, mieux c’est. Mesure la dispersion intra/inter-cluster.